---
title: "Example workflow using the `pacheck` R package"
author: "X. Pouwels"
date: "`r paste(Sys.Date())`"
output: 
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
---

```{r setup, include = FALSE}
library(pacheck)
library(knitr)
library(plotly)
library(ggplot2)
data(df_pa)
```

# Introduction
This article describes an example workflow for the use of the 
## 1.	Upload of original health economic model inputs and outputs
 


```{r calc_nb, echo = T}
df_pa <- calculate_nb(df = df_pa,
                      e_int = "t_qaly_d_int",
                      e_comp = "t_qaly_d_comp",
                      c_int = "t_costs_d_int",
                      c_comp = "t_costs_d_comp",
                      wtp = 80000)# calculate net benefits

```

## 2. Investigate model inputs and outputs
### a.	Summary statistics of (user-selected) model inputs and outputs
*To examine whether cost inputs are always positive for instance*

```{r smmr, echo = T}
df <- generate_sum_stats(df_pa)
kable(df)
rm(df)
```

### b.	Correlation matrix inputs (and outputs)
Question Karel:  
- Karel: kan dit met kleuren om de sterke van de associatie te onderbouwen?   
```{r corr, echo = T}
generate_cor(df_pa)
```

### c. Inspect types of variables

#### Perform quick checks on input values
*Are utility values/probabilities between 0-1, costs positive etc...*
```{r quick_check, echo = T}
do_quick_check(df = df_pa,
               v_utilities = c("u_pfs", "u_pd"),
               v_costs = c("c_pfs", "c_pd", "c_thx"),
               v_rr = "rr"
               )
```

#### Perform quick comparison discounted and undiscounted results
*Are utility values/probabilities between 0-1, costs positive etc...*
```{r quick_discount_check, echo = T}
do_discount_check(df = df_pa,
                   v_outcomes = c("t_qaly_comp", "t_qaly_int"),
                   v_outcomes_d = c("t_qaly_d_comp", "t_qaly_d_int")
                   )
```

#### Positive variables
*Are these variables strictly positive?* 
```{r check_positive, echo = T}
check_positive("c_pfs", "c_pd", df = df_pa)
```

#### Variables between 0-1
*Are these variables strictly positive?* 
```{r check_positive2, echo = T}
check_binary("u_pfs", "p_pfspd", df = df_pa)
```

#### Sum of probabilities
*To check whether the sum is lower than or equal to, or equal to 1* 

```{r check_sum, echo = T}
check_sum_probs("p_pfspd", "p_pfsd", df = df_pa, check = "lower") # output is a text
```

### d.	Histogram, density distribution of (user-selected) model inputs and outputs
*To visually investigate the parameter distributions*

#### Single parameter
```{r dist_plot, echo = T}
p_1 <- vis_1_param(df = df_pa,
            param = "u_pfs",
            binwidth = NULL,
            type = "histogram",
            dist = c("norm", "beta", "gamma", "lnorm"))
p_1

paste("Probability to be in user-defined range: ",
      check_range(df_pa,
                  outcome = "u_pfs",
                  min_val = 0.77,
                  max_val = 0.80
                  ), "%") # add this to plot? + lines of min/ max on plot?
```

### Two parameters
```{r vis_2_pars, wcho = T}
p_2p <- vis_2_params(df = df_pa,
                     param_1 = "u_pfs",
                     param_2 = "u_pd",
                     slope = 1,
                     check = "param_2 > param_1")
p_2p
```

### e.	Possibility to fit user-selected distributions (beta, gamma, lognormal, normal) + visualisation + parameters of the fitted distribution.
*To cross check with parameters reported in documentation/report/ journal article, as an implementation check*  
- To do XP: Add probabilistic mean value per distribution  
```{r dist_plot_2, echo = T}
p_2 <- vis_1_param(df = df_pa,
            param = "u_pfs",
            binwidth = NULL,
            type = "density",
            dist = c("norm", "beta", "gamma", "lnorm"),
            user_dist = "beta",
            user_param_1 = 0.8,
            user_param_2 = 0.2,
            user_mean = 0.75)
p_2
```

#### Distributions' parameters & statistical fit
```{r fit_dists, echo = T}
l_dist <- fit_dist(df = df_pa,
                   param = "u_pfs",
                   dist = c("norm", "beta", "gamma", "lnorm"))
l_dist[[1]]
l_dist[[2]]
```

## 3.	Investigate model outputs
### a.	Incremental cost-effectiveness plane & summary
Questions met Karel te bespreken:  
- Interactive plot where you can click on a dot, or select some dots and see which input parameters combination has led to these outputs --> ook mogelijkheid om een bepaalde 'gebied' te selecteren (invoeren) en te zien welke inputs daarbij behoren.  
- Combineren van de plot hierbeneden met de histogrammen van de waarden op de x en y as, of als niet overzichtelijk: met ticks op de axes als er een datapunt is.  

```{r dist_plot_2p, echo = T}
p_3 <- plot_ice(
  df = df_pa,
  e_int = "t_qaly_d_int",
  e_comp = "t_qaly_d_comp",
  c_int = "t_costs_d_int",
  c_comp = "t_costs_d_comp",
  wtp = 8000
)
p_3
p_3_interact <- ggplotly(p_3)
p_3_interact

summary_ice(df_pa,
           "inc_qaly",
           "inc_costs")
```


- Plot hierboven koppelen aan een graphs van 1 en 2 input parameters. Al gedaan in tentative shiny app voor onderwijs: selectie van punten in de 'input graph' wordt gehighlight in andere plot. Voorbeeld, laatste tabs van volgende shiny app: `shiny::runGitHub("Teaching", "Xa4P", subdir = "Basics/shiny_app_cea/", ref = "main")`.  

### b.	Cost-effectiveness acceptability curve.
```{r ceac, echo = T}
df_ceac <- calculate_ceac(df = df_pa,
                     e_int = "t_qaly_d_int",
                     e_comp = "t_qaly_d_comp",
                     c_int = "t_costs_d_int",
                     c_comp = "t_costs_d_comp")

plot_ceac(df = df_ceac,
          wtp = "WTP_threshold")
df_ceac
```

### c.	Histogram and density distribution of total and incremental costs and effects.
**Can use the function above!  **

### d.	Convergence graph of outcomes
```{r conv, echo = T}
plot_convergence(df = df_pa,
                 outcome = "iNMB"
                 )
```

### e.	Check whetherthe mean quality of life outcome of each iteration remain between the maximum and minimum utility values of the specific iteration.
```{r mean_qol, echo = T}
check_mean_qol(df = df_pa,
               t_ly = "t_ly_comp",
               t_qaly = "t_qaly_comp",
               u_values = c("u_pfs", "u_pd")
               )
```

## 4.	Investigate relation between inputs and outputs
### Single  

- To do XP: Add R^2^  

```{r fit_metamod_single, echo = T}
lm_rr <- fit_lm_metamodel(df = df_pa,
                          x_vars = "rr",
                          y_var = "inc_qaly")
lm_pred <- unlist(predict(lm_rr$fit, data.frame(rr = df_pa$rr)))
df_obs_pred <- data.frame(
  Values = df_pa$rr,
  Observed = df_pa$inc_qaly,
  Predicted = lm_pred
)
ggplot(data = df_obs_pred, aes(x = Values, y = Observed)) +
  geom_point(shape = 1, colour = "lightgrey") +
  geom_smooth(method = "lm") +
  theme_bw()
plot(lm_rr$fit)
```

### Multiple

```{r fit_metamod_mult, echo = T}
lm_full <- fit_lm_metamodel(df = df_pa,
                            x_vars = c("rr",
                                       "u_pfs",
                                       "u_pd",
                                       "c_pfs",
                                       "c_pd",
                                       "c_thx",
                                       "p_pfspd",
                                       "p_pfsd",
                                       "p_pdd"),
                            y_var = "inc_qaly")
lm_pred_full <- predict(lm_full$fit, data.frame(rr = df_pa$rr,
                            u_pfs = mean(df_pa$u_pfs),
                            u_pd = mean(df_pa$u_pd),
                            c_pfs = mean(df_pa$c_pfs),
                            c_pd = mean(df_pa$c_pd),
                            c_thx = mean(df_pa$c_thx),
                            p_pfspd = mean(df_pa$p_pfspd),
                            p_pfsd = mean(df_pa$p_pfsd),
                            p_pdd = mean(df_pa$p_pdd)))

df_obs_pred_full <- data.frame(
  Values = df_pa$rr,
  Observed = df_pa$inc_qaly,
  Predicted = lm_pred_full
)

ggplot(data = df_obs_pred_full, aes(x = Values, y = Observed)) +
  geom_point(shape = 1, colour = "lightgrey") +
  geom_line(data = df_obs_pred_full, aes(x = Values, y = Predicted), colour = "blue") +
  theme_bw()

plot(lm_full$fit)
```

## 5. Predictions based on metamodel  
```{r metamodel_pred, echo = T}
# Predicting using metamodel fitted above
predict(
  lm_full$fit,
  data.frame(
    rr = 0.9,
    u_pfs = 0.75,
    u_pd = 0.4,
    c_pfs = 1000,
    c_pd = 2000,
    c_thx = 0,
    p_pfspd = 0.5,
    p_pfsd = 0.3,
    p_pdd = 0.4
  )
)
```

# Other activities/ questions/ to do's
- Two-way sensitivity analysis based on metamodel.  
- Include other functional forms of metamodels  
- Check results of deterministic sensitivity analyses using original model and metamodel.  
- XP/Karel to do: Add possibility of having multiple scenarios loaded. --> door selectie aan het begin van de app?    
- Shapley values, zou dat kunnen ? Zou het mogelijk zijn om dat op de originele data set te doen? **KernelExplainer** on this github: https://github.com/slundberg/shap. Of is dit iets? https://github.com/nredell/shapFlex, maar ziet eruit dat je ook een model moet fitten (niet model agnostic)  
- Check whether violin plot have added value  
